{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Classical-Quantum Hybrid Convolutional Neural Network",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9RbYeYjjV4s"
      },
      "source": [
        "\n",
        "## Getting Started and Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEEGUnKYx9FG"
      },
      "source": [
        "!pip install pennylane"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dvNY80wdxCh"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnqh-V9Xr88f"
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pennylane as qml\n",
        "import torchvision\n",
        "from torch import nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na-rqgN1j1N-"
      },
      "source": [
        "## Processing Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZrcyATrkkFz"
      },
      "source": [
        "%cd /content/drive/My Drive/hiptopathologic-cancer-data/histopathologic-cancer-detection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWOYcPPXsUHj"
      },
      "source": [
        "df = pd.read_csv(\"./train_labels.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZL6NUwBswuT"
      },
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class HistopathologicDataset(Dataset):\n",
        "    def __init__(self, df, datadir, transform=None):\n",
        "        self.fnames = [f\"{datadir}/{i}.tif\" for i in df.id]\n",
        "        self.labels = df.label.tolist()\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.fnames)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        img = cv2.imread(self.fnames[index])\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, self.labels[index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH6ZRTNWsz1F"
      },
      "source": [
        "from torchvision import transforms, models\n",
        "\n",
        "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.CenterCrop((48, 48)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "valid_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.CenterCrop((48, 48)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx4uYOc3s25-"
      },
      "source": [
        "split = int(0.8 * len(df))\n",
        "batch_size = 64\n",
        "train_dataset = HistopathologicDataset(df[:split], \"./train\", train_transforms)\n",
        "valid_dataset = HistopathologicDataset(df[split:], \"./train\", valid_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lunXejcEoNCi"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS-H7UKHZqIg"
      },
      "source": [
        "def H_layer(nqubits):\n",
        "    for idx in range(nqubits):\n",
        "        qml.Hadamard(wires=idx)\n",
        "\n",
        "\n",
        "def RY_layer(w):\n",
        "    for idx, element in enumerate(w):\n",
        "        qml.RY(element, wires=idx)\n",
        "\n",
        "\n",
        "def entangling_layer(nqubits):\n",
        "    for i in range(0, nqubits - 1, 2): \n",
        "        qml.CNOT(wires=[i, i + 1])\n",
        "    for i in range(1, nqubits - 1, 2):  \n",
        "        qml.CNOT(wires=[i, i + 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqI-cmx_0O1r"
      },
      "source": [
        "n_qubits = 4 \n",
        "step = 0.0004              \n",
        "batch_size = 4              \n",
        "q_depth = 6                \n",
        "gamma_lr_scheduler = 0.1   \n",
        "q_delta = 0.01              \n",
        "rng_seed = 3         "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjq11GquzC8D"
      },
      "source": [
        "dev = qml.device(\"lightning.qubit\", wires=n_qubits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjcEqLfScsZr"
      },
      "source": [
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def quantum_net(q_input_features, q_weights_flat):\n",
        "    q_weights = q_weights_flat.reshape(q_depth, n_qubits)\n",
        "    H_layer(n_qubits)\n",
        "    RY_layer(q_input_features)\n",
        "    for k in range(q_depth):\n",
        "        entangling_layer(n_qubits)\n",
        "        RY_layer(q_weights[k])\n",
        "    exp_vals = [qml.expval(qml.PauliZ(position)) for position in range(n_qubits)]\n",
        "    return tuple(exp_vals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVLYfz4ncx_n"
      },
      "source": [
        "class DressedQuantumNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.pre_net = nn.Linear(512, n_qubits)\n",
        "        self.q_params = nn.Parameter(q_delta * torch.randn(q_depth * n_qubits))\n",
        "        self.post_net = nn.Linear(n_qubits, 2)\n",
        "\n",
        "    def forward(self, input_features):\n",
        "        pre_out = self.pre_net(input_features)\n",
        "        q_in = torch.tanh(pre_out) * np.pi / 2.0\n",
        "        q_out = torch.Tensor(0, n_qubits)\n",
        "        q_out = q_out.to(device)\n",
        "        for elem in q_in:\n",
        "            q_out_elem = quantum_net(elem, self.q_params).float().unsqueeze(0)\n",
        "            q_out = torch.cat((q_out, q_out_elem))\n",
        "        return self.post_net(q_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48kYHFcqs9_p"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgGnU4-xs7F1"
      },
      "source": [
        "model_hybrid = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "for param in model_hybrid.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model_hybrid.fc = DressedQuantumNet()\n",
        "\n",
        "model_hybrid = model_hybrid.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjnZp_VltBmN"
      },
      "source": [
        "def train(train_loader, model, criterion, optimizer, scheduler):\n",
        "    total_loss = 0.0\n",
        "    size = len(train_loader.dataset)\n",
        "    num_batches = size // train_loader.batch_size\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        model = nn.DataParallel(model)\n",
        "\n",
        "    model.train()\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        print(f\"Training: {i}/{num_batches}\", end=\"\\r\")\n",
        "        \n",
        "        scheduler.step()\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "        loss.backward() \n",
        "        optimizer.step()\n",
        "        \n",
        "    return total_loss / size\n",
        "\n",
        "def validate(valid_loader, model, criterion):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total_correct = 0\n",
        "        total_loss = 0.0\n",
        "        size = len(valid_loader.dataset)\n",
        "        num_batches = size // valid_loader.batch_size\n",
        "        for i, (images, labels) in enumerate(valid_loader):\n",
        "            print(f\"Validation: {i}/{num_batches}\", end=\"\\r\")\n",
        "            \n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            total_correct += torch.sum(preds == labels.data)\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            \n",
        "        return total_loss / size, total_correct.double() / size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vj5UDJGtD19"
      },
      "source": [
        "def fit(model, num_epochs, train_loader, valid_loader):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
        "    scheduler = 0.1\n",
        "    print(\"epoch\\ttrain loss\\tvalid loss\\taccuracy\")\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train(train_loader, model, criterion, optimizer, scheduler)\n",
        "        valid_loss, valid_acc = validate(valid_loader, model, criterion)\n",
        "        print(f\"{epoch}\\t{train_loss:.5f}\\t\\t{valid_loss:.5f}\\t\\t{valid_acc:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIgBgLfqowUm"
      },
      "source": [
        "## Parallelized and Distributed across Computational Resources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC3z1lwRothJ"
      },
      "source": [
        "class DataParallelModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.block1 = nn.Linear(10, 20)\n",
        "\n",
        "        # wrap block2 in DataParallel\n",
        "        self.block2 = nn.Linear(20, 20)\n",
        "        self.block2 = nn.DataParallel(self.block2)\n",
        "\n",
        "        self.block3 = nn.Linear(20, 20)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFqNDdEOo8fJ"
      },
      "source": [
        "def data_parallel(module, input, device_ids, output_device=None):\n",
        "    if not device_ids:\n",
        "        return module(input)\n",
        "\n",
        "    if output_device is None:\n",
        "        output_device = device_ids[0]\n",
        "\n",
        "    replicas = nn.parallel.replicate(module, device_ids)\n",
        "    inputs = nn.parallel.scatter(input, device_ids)\n",
        "    replicas = replicas[:len(inputs)]\n",
        "    outputs = nn.parallel.parallel_apply(replicas, inputs)\n",
        "    return nn.parallel.gather(outputs, output_device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MwGcmqyp0jp"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "from torch.multiprocessing import Process"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JzkJjBnpEKe"
      },
      "source": [
        "\" partioning dataset to run across computers \"\n",
        "\n",
        "class Partition(object):\n",
        "    def __init__(self, data, index):\n",
        "        self.data = data\n",
        "        self.index = index\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.index)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data_idx = self.index[index]\n",
        "        return self.data[data_idx]\n",
        "\n",
        "\n",
        "class DataPartitioner(object):\n",
        "    def __init__(self, data, sizes=[0.7, 0.2, 0.1], seed=1234):\n",
        "        self.data = data\n",
        "        self.partitions = []\n",
        "        rng = Random()\n",
        "        rng.seed(seed)\n",
        "        data_len = len(data)\n",
        "        indexes = [x for x in range(0, data_len)]\n",
        "        rng.shuffle(indexes)\n",
        "\n",
        "        for frac in sizes:\n",
        "            part_len = int(frac * data_len)\n",
        "            self.partitions.append(indexes[0:part_len])\n",
        "            indexes = indexes[part_len:]\n",
        "\n",
        "    def use(self, partition):\n",
        "        return Partition(self.data, self.partitions[partition])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKlpmLhFrm8h"
      },
      "source": [
        "def average_gradients(model):\n",
        "    \"\"\" Gradient averaging. \"\"\"\n",
        "    size = float(dist.get_world_size())\n",
        "    for param in model.parameters():\n",
        "        dist.all_reduce(param.grad.data, op=dist.reduce_op.SUM, group=0)\n",
        "        param.grad.data /= size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFPhi2l0oRYJ"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_4BFuixtGI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59be9252-df07-4cb3-8cbc-55b88fa4113b"
      },
      "source": [
        "model_hybrid = model_hybrid.to(device)\n",
        "fit(model_hybrid, 20, train_loader, valid_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch\ttrain loss\tvalid loss\taccuracy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wxx_4TVFtKOu"
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "def results(model, valid_loader):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    actual = []\n",
        "    with torch.no_grad():\n",
        "         for images, labels in valid_loader:\n",
        "            outputs = model(images.to(device))\n",
        "            preds.append(outputs.cpu()[:,1].numpy())\n",
        "            actual.append(labels.numpy())\n",
        "    return np.concatenate(preds), np.concatenate(actual)\n",
        "\n",
        "preds, actual = results(model_hybrid, valid_loader)\n",
        "fpr, tpr, _ = roc_curve(actual, preds)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "plt.plot(fpr, tpr, label=f\"ROC curve (area = {auc(fpr, tpr):.3f})\")\n",
        "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristics'); plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}